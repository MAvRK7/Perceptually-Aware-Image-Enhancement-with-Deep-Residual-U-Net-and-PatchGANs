# Perceptually Aware Image Enhancement with Deep Residual U-Net and PatchGANs

Image enhancement is a critical component of computer vision, aimed at improving both perceived quality and technical detail in images. This work introduces a
novel image enhancement approach that used a U-Net-based generator combined with residual connections and a Patch-based Generative Adversarial Network (PatchGAN) as the discriminator. The method was further strengthened by a perceptual loss function using a VGG 16 network, ensuring that the enhanced images not only exhibited improved colour sharpness and clarity but also retained critical high level features of the original image. The proposed model demonstrates significant improvements in structural similarity, achieving an average SSIM (Structural Similarity Index) of 0.9270 and FSIM (Feature Similarity Index) of 0.9998. These results indicate both perceptual and structural enhancement. Furthermore, the model efficiently generates high quality images with minimal training. Empirical results showed that the method consistently outperforms conventional approaches
in visual appeal and computational efficiency, making it relevant to real-world applications, such as radiology, self-driving vehicles, and low light photography.

My contribution: Complete development of the proposed model

This work has been submitted to The Visual Computer Springer Journal and is currently being reviewed.
