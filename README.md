# Perceptually Aware Image Enhancement with Deep Residual U-Net and PatchGANs

Image enhancement is a key aspect of computer vision, aiming to enhance both the perceived quality and technical details of images. This paper introduces a novel image enhancement approach that utilises a U-Net-based generator combined with residual connections and patch-based Generative Adversarial Network (PatchGAN) as the discriminator. The method is further strengthened by perceptual loss using a pre-trained VGG16 network, ensuring the enhanced images not only exhibit improved colour sharpness and clarity but also retain critical high-level features. The proposed model demonstrates significant improvements in structural similarity, achieving an average SSIM (Structural Similarity Index) of 0.9270 and FSIM (Feature Similarity Index) of 0.9998, indicating both perceptual and structural enhancement. Furthermore, the model efficiently generates high-quality images with minimal training, requiring only two epochs. Experimental results show that the method consistently outperforms conventional approaches with regard to visual appeal and computational efficiency, making it well suited for real-world applications, such as medical imaging, autonomous vehicles, and low-light photography.

My contribution: Complete development of the proposed model

This work has been submitted to The 3nd International conference on Machine Learning and Data Engineering (ICMLDE 2024)
